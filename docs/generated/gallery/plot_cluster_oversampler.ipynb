{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nClustering-based over-sampling\n==============================\n\nThis example illustrates the data generation \nprocess and the performance of various \nover-samplers when clustering-based over-sampling \nis used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Georgios Douzas <gdouzas@icloud.com>\n# Licence: MIT\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom clover.over_sampling import ClusterOverSampler\nfrom imblearn.over_sampling import SMOTE, BorderlineSMOTE, RandomOverSampler\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.base import clone\nfrom sklearn.cluster import AgglomerativeClustering, KMeans\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\n\nRANDOM_STATE = 0\nOVERSAMPLERS = [\n    RandomOverSampler(random_state=RANDOM_STATE),\n    SMOTE(random_state=RANDOM_STATE + 1),\n    BorderlineSMOTE(random_state=RANDOM_STATE + 2),\n]\nKMEANS = KMeans(random_state=RANDOM_STATE, n_clusters=100)\n\n\ndef generate_imbalanced_data():\n    \"\"\"Generate imbalanced data.\"\"\"\n    X, y = make_classification(\n        n_classes=3,\n        class_sep=0.8,\n        weights=[0.01, 0.05, 0.94],\n        n_informative=2,\n        n_redundant=0,\n        n_repeated=0,\n        n_features=2,\n        n_clusters_per_class=1,\n        n_samples=2000,\n        random_state=RANDOM_STATE,\n    )\n    return X, y\n\n\ndef plot_data(X, y, oversampler, ax):\n    \"\"\"Plot original or resampled data.\"\"\"\n    if oversampler is None:\n        X_res, y_res = X, y\n        title = 'Original data'\n    else:\n        oversampler = clone(oversampler)\n        X_res, y_res = oversampler.fit_resample(X, y)\n        if not isinstance(oversampler, ClusterOverSampler):\n            ovs_name = oversampler.__class__.__name__\n            title = f'Resampling using {ovs_name}'\n        else:\n            clusterer_name = oversampler.clusterer.__class__.__name__\n            ovs_name = oversampler.oversampler_.__class__.__name__\n            title = f'Resampling using {clusterer_name}-{ovs_name}'\n    ax.scatter(X_res[:, 0], X_res[:, 1], c=y_res, alpha=0.8, edgecolor='k')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    ax.spines['left'].set_position(('outward', 10))\n    ax.spines['bottom'].set_position(('outward', 10))\n    ax.set_title(title)\n\n\ndef compare_f1_scores(X_train, X_test, y_train, y_test, clf, oversampler, clusterer):\n    \"\"\"Compare F1 scores of oversamplers with and without clustering.\"\"\"\n    ovs_clf = make_pipeline(clone(oversampler), clf)\n    clr_ovs_clf = make_pipeline(ClusterOverSampler(clone(oversampler), clusterer), clf)\n    y_pred = ovs_clf.fit(X_train, y_train).predict(X_test)\n    y_pred_clr = clr_ovs_clf.fit(X_train, y_train).predict(X_test)\n    ovs_name = oversampler.__class__.__name__\n    clr_name = clusterer.__class__.__name__\n    ovs_score = f1_score(y_test, y_pred, average='macro')\n    clr_ovs_score = f1_score(y_test, y_pred_clr, average='macro')\n    return pd.DataFrame(\n        [[ovs_score, clr_ovs_score]],\n        columns=['No clustering', clr_name],\n        index=[ovs_name],\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate imbalanced data\n------------------------\n\n\nWe are generating a highly imbalanced multi-class data set, using\n``make_classification`` from scikit-learn.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = generate_imbalanced_data()\n_, ax = plt.subplots(1, 1, figsize=(15, 7))\nplot_data(X, y, None, ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Effect of clustering to over-samplers\n-------------------------------------\n\nClustering based over-sampling allows to identify areas of the input space\nwhich are appropriate to generate artificial data. Therefore, the generation\nof noisy samples is avoided and the within-classes imbalanced issue is also\naddressed. The next plots show the resampled data when clustering is applied,\ncomparing them to the resampled data of the initial over-samplers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\nfor (ax1, ax2), oversampler in zip(axs, OVERSAMPLERS):\n    plot_data(X, y, clone(oversampler), ax1)\n    plot_data(X, y, ClusterOverSampler(oversampler, KMEANS), ax2)\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performance evaluation of clustering based over-sampling\n--------------------------------------------------------\n\nWe are evaluating various over-samplers using F1-score as evaluation metric\non a test set. The scores with and without clustering are compared.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = GradientBoostingClassifier(random_state=RANDOM_STATE)\ndata = train_test_split(X, y, random_state=RANDOM_STATE)\nscores = pd.DataFrame()\nfor oversampler in OVERSAMPLERS:\n    X_train, X_test, y_train, y_test = data\n    scores = scores.append(compare_f1_scores(X_train, X_test, y_train, y_test, clf, oversampler, KMEANS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We repeat the process for AgglomerativeClustering instead of KMeans.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aff_prop = AgglomerativeClustering(n_clusters=100)\nscores = pd.DataFrame()\nfor oversampler in OVERSAMPLERS:\n    X_train, X_test, y_train, y_test = data\n    scores = scores.append(compare_f1_scores(X_train, X_test, y_train, y_test, clf, oversampler, aff_prop))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}